{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LYYTEun_I2f"
   },
   "source": [
    "# Welcome !\n",
    "This CoLab notebook is a walkthough on how to use my function **expertiseFinder_NameOrInst()** *(plus some bonus functions)* in the .py file **ExpertiseFinder_MSI.py**. The purpose of this function is to determine researchers at a specific institutions that have a presence in the ADS NASA database. The \"Expertise Finder\" detects what researchers are from the target institution by querying NASA ADS using the institution name, then pulling out the author name of papers whose first author is affiliated with the target institution. The code then focuses on their astronomical expertise through selecting publication in astronomical journals (e.g. ApJ, MNRAS, SPIE).\n",
    "\n",
    "The primary goal of this tutorial is to walk the user through the process of using said function on provided data files and prepare them for using the function on their own.\n",
    "\n",
    "The items you will need to run this code are listed below:\n",
    "1. The file **ExpertiseFinder_MSI.py**.\n",
    "2. The supporting file **TextAnalysis.py**.\n",
    "3. A file of ignorable \"stop words\" and its directory path in Google Drive: **stopwords.csv**.\n",
    "4. For the BONUS section, the file **NHFPFellows_Sample.csv** as an input.\n",
    "5. Your own **NASA ADS API token**. This is a long string of characters generated by ADS that gives you acces to their API. You can find instructions on how to get an ADS token [here](https://ads.readthedocs.io/en/v1/api-key.html).\n",
    "\n",
    "Please make sure you have these items available before starting this tutorial. If you do not have access to these files, please contact maire.volz@nasa.gov or antonino.cucchiara@nasa.gov. Thank you !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfyyo4JeqNxq"
   },
   "source": [
    "### The \"Expertise Finder\"\n",
    "The function has the following arguments:\n",
    "1. **token** = an ads API token  from https://ui.adsabs.harvard.edu/help/api/ (*string*)\n",
    "2. **directorypath** = the file location of 'stopwords.txt' on your device (*string*)\n",
    "3. **inst** = the institution name of interest (*string*)\n",
    "4. **name** ('LastName, FirstName') = an optional argument that, when not 'None', searches ADS for a specific author's name at a specific institution (*string*)\n",
    "5. **refereed** (True or False) = an optional argument that toggles whether NASA ADS search results need to be peer-refereed (*boolean*)\n",
    "6. **year** = an optional argument that determines a cutoff point for consideration; papers published before this year will not be considered (*int*)\n",
    "7. **strictness** = an optional keyword argument that determines how strict the function will be when filtering ADS results (can be one of three *strings*: 'default', 'low', or 'high')\n",
    "8. **fileName** ('___.csv') = an optional keyword argument that defines the name under which the newData output is saved to the user's device (*string* with default \"expertiseFinder_output.csv\")\n",
    "\n",
    "Running this function will return the following:\n",
    "\n",
    "1. **newData** = a spreadsheet containing information on author name, institution, paper titles, publication years, keywords, abstracts, top 10 words, bi-grams, and tri-grams, and a \"CLEAN\" or \"DIRTY\" classification.\n",
    "\n",
    "In this tutorial, we will only be defining the arguments **token**, **directorypath**, **inst**, **year**, and **strictness**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgQAOxSSbQN8"
   },
   "source": [
    "### STEP 1: Import necessary files and packages to this notebook.\n",
    "In order to run the \"Expertise Finder\", we must define the location of and upload the necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v513yHWe_nUG"
   },
   "outputs": [],
   "source": [
    "# Install the ADS library\n",
    "!pip install ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nRZwiLvdac2"
   },
   "outputs": [],
   "source": [
    "# Before I forget, though, you should import the outside packages that this code needs to run.\n",
    "import ads\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpVElBuHayUY"
   },
   "outputs": [],
   "source": [
    "# Define the directory path of the  stopwords file. If it is in the same directory as this notebook, topdirectory will remain blank. \n",
    "# Modify the string below if 'stopowrds.txt' is in another directory:\n",
    "topdirectory = ''\n",
    "stopwordspath = topdirectory + 'stopwords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsGoP6Wbb1CI"
   },
   "outputs": [],
   "source": [
    "# Now, we will import the functions from TextAnalysis.py and ExpertiseFinder_MSI.py.\n",
    "import TextAnalysis as TA\n",
    "import ExpertiseFinder_MSI as EF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeKTeaBzCZCw"
   },
   "source": [
    "**Hooray !** Now all of our necessary files, packages, and modules are imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2bpFxjxDQOa"
   },
   "source": [
    "### STEP 2: Running the code.\n",
    "In this step, we will accomplish one of our main goals: running the function **expertiseFinder_NameOrInst()** on an institution name of our choice.\n",
    "\n",
    "In this tutorial, we will only be defining the arguments **token**, **directorypath**, **inst**, **year**, **strictness**, and **fileName**. By enabling **inst** and not **name** at the same time, this means our code will search of ALL top author names associated with the institution that we defined. If we were to define both **inst** and **name**, the code would \"switch modes\", in a way: it would only search for the papers written by a single author (**name**) at while at the institution (**inst**).\n",
    "\n",
    "The **strictness** keyword warrants more explanation. The user's choice of \"default\", \"low\", or \"high\" will decide what set of filters are applied to each paper belonging to the top authors of an institution.\n",
    "\n",
    "* LOW strictness triggers filters that permit an exact author match, a close institution match, or the presence of a journal name (ApJ, MNRAS, SPIE, AJ, Science, PASP, Nature, Arxiv).\n",
    "* HIGH strictness triggers filters that permit a relevant journal name AND an exact author match or a close institution match (the provided institution name string is included in the official affiliation name).\n",
    "* DEFAULT strictness triggers filters that permit a close author match AND close institution match, OR an exact author match, OR a close institution match, OR a relevant journal name.\n",
    "In this tutorial, we will use the \"default\" filter strictness.\n",
    "\n",
    "In the output **newData**, the \"CLEAN\" or \"DIRTY\" classification is determined by whether a specific paper met the filter qualifications specified by the **strictness** keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCEQef60QY13"
   },
   "outputs": [],
   "source": [
    "# First, define your ADS token:\n",
    "token = 'blah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxgiT3wdCbwv"
   },
   "outputs": [],
   "source": [
    "# Let's do it !\n",
    "newData = EF.expertiseFinder_NameOrInst(token, stopwordspath, 'University of the Virgin Islands', year = 2000, strictness = 'default', fileName = topdirectory+'UVI_topAuthors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nmy5dDNdQzO6"
   },
   "outputs": [],
   "source": [
    "# Check out what you made !\n",
    "newData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNl1tlFrXnnr"
   },
   "source": [
    "The cell above contains one final output of this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8oBf3kCoXZu"
   },
   "source": [
    "Before we end here, make sure to save your output(s) ! The expertise finder does automatically save your file as a .csv, but if you would like to instead have it as an Excel document, run this cell separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-M8kxmxTsn5"
   },
   "outputs": [],
   "source": [
    "# Save the output in a .excel file run the following command:\n",
    "newData.to_excel(topdirectory+'UVI_topAuthors.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl2Vt2i5sX_X"
   },
   "source": [
    "Any new files created within this tutorial should now appear in the same directory as this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS pt. 1: Search a single name and institution.\n",
    "The function **expertiseFinder_NameOrInst()** has another \"mode\" where, instead of searching only for an institution name and returning several author names from that insitution, a user can search for a single name at a single instition. *This is done by defining the optional keyword \"name\".*\n",
    "\n",
    "In this example, we will search for information on Joshua Pepper while he was working at Lehigh University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new keywords.\n",
    "josh = 'Pepper, Joshua'\n",
    "lehigh = 'Lehigh University'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joshData = EF.expertiseFinder_NameOrInst(token, stopwordspath, inst = lehigh, name = josh, year = 2000, strictness = 'default', fileName = topdirectory+'joshData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it out !\n",
    "joshData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS pt. 2: Search for several names in a large spreadsheet.\n",
    "While the function **expertiseFinder_NameOrInst()** was built for processing single names or institutions, its parent function **expertiseFinder()** can process large spreadsheets of researcher names and their affiliate institutions. \n",
    "\n",
    "The **expertiseFinder()** has some slightly different keywords that are detailed below:\n",
    "1. **rawFile** = a Pandas data frame containing at least the following two columns: **\"LastName, FirstName\"** (containing researcher names) and **\"Institution Name\"** (containting those researchers' affiliate institution.\n",
    "2. **start** = the index of **rawFile** at which the function should begin searching ADS (*int*)\n",
    "3. **count** = the number of rows after **start** that the function should continue searching ADS (*int*). This keyword is put in place to prevent a user from overpassing the 5000-queries-a-day limit from ADS API.\n",
    "\n",
    "**expertiseFinder()** also contains optional keywords **year** and **strictness** but does NOT have keywords **inst**, **name**, or **refereed**.\n",
    "\n",
    "As for outputs, instead of returning a single data frame, **expertiseFinder()** returns TWO:\n",
    "1. **top10Df** = a Pandas data frame containing results from ADS that are considered \"clean\", or match the \"strictness\" filters.\n",
    "2. **top10DirtyDf** = a Pandas data frame containing resutls from ADS that are considered \"dirty\", or did NOT match the \"strictness\" filters.\n",
    "\n",
    "The cells to follow display how this parent function analyses sample data from NHFP fellowship recipients and their host institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data to analyse:\n",
    "NHFPdf = pd.read_csv('NHFPFellows_Sample.csv')\n",
    "NHFPdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the sample we will be analysing. \n",
    "\n",
    "**PLEASE NOTE: In order for** expertiseFinder() **to analyze a spreadsheet, there must be at least two columns named** \"LastName, FirstName\" **and** \"Institution Name\"**.** So make sure that, when you use this function on your own data, you rename some columns !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining where you would like to start and end analysis.\n",
    "start = 12\n",
    "count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, run the code !\n",
    "NHFPData = EF.expertiseFinder(token, stopwordspath, NHFPdf, start, count, year = 2000, strictness = 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData = NHFPData[0]\n",
    "dirtyData = NHFPData[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtyData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorial. If you have any questions, comments, concerns, or encounter an bugs, please do not hestitate to contact maire.volz@nasa.gov or antonino.cucchiara@nasa.gov. Happy coding !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXrB6QVTsVya"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
